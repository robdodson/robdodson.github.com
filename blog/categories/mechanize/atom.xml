<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Mechanize | Rob Dodson talks internets]]></title>
  <link href="http://robdodson.me/blog/categories/mechanize/atom.xml" rel="self"/>
  <link href="http://robdodson.me/"/>
  <updated>2014-03-23T08:29:42-07:00</updated>
  <id>http://robdodson.me/</id>
  <author>
    <name><![CDATA[Rob Dodson]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Quick Spider Example]]></title>
    <link href="http://robdodson.me/blog/2012/06/21/quick-spider-example/"/>
    <updated>2012-06-21T01:27:00-07:00</updated>
    <id>http://robdodson.me/blog/2012/06/21/quick-spider-example</id>
    <content type="html"><![CDATA[<p>``` ruby
require 'mechanize'</p>

<h1>Create a new instance of Mechanize and grab our page</h1>

<p>agent = Mechanize.new
page = agent.get('http://robdodson.me/blog/archives/')</p>

<h1>Find all the links on the page that are contained within</h1>

<h1>h1 tags.</h1>

<p>post_links = page.links.find_all { |l| l.attributes.parent.name == 'h1' }
post_links.shift</p>

<h1>Follow each link and print out its title</h1>

<p>post_links.each do |link|</p>

<pre><code>post = link.click
doc = post.parser
p doc.css('.entry-title').text
</code></pre>

<p>end
```
Having a horrible time getting anything to run tonight. The code from above is a continuation from yesterday's post except this time we're finding every link on the page, then following that link and spitting out its title. Using this formula you could build something entirely recursive which acts as a full blown spider.</p>

<p>Unfortunately getting this to integrate into the existing app is not working for me tonight. Coding anything after 11 pm is usually a bad call, so I'm going to shut it down and try again in the morning.</p>

<p>You should follow me on Twitter <a href="http://twitter.com/rob_dodson">here.</a></p>

<ul class="personal-stats">
    <li>Mood: Tired, Annoyed</li>
    <li>Sleep: 6</li>
    <li>Hunger: 0</li>
    <li>Coffee: 1</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Crawling pages with Mechanize and Nokogiri]]></title>
    <link href="http://robdodson.me/blog/2012/06/20/crawling-pages-with-mechanize-and-nokogiri/"/>
    <updated>2012-06-20T00:09:00-07:00</updated>
    <id>http://robdodson.me/blog/2012/06/20/crawling-pages-with-mechanize-and-nokogiri</id>
    <content type="html"><![CDATA[<p>Short post tonight because I spent so much time figuring out the code. It's late and my brain is firing on about 1 cylinder so it took longer than I expected to get everything working.</p>

<p>The scraper that I'm building is supposed to work like a spider and crawl of the pages of my blog. I wasn't sure what the best way to do that was so I started Googling and came up with <a href="http://mechanize.rubyforge.org/">Mechanize.</a> There are other tools built on top of Mechanize, like <a href="https://github.com/felipecsl/wombat">Wombat</a>, but since my task is so simple I figured I could just write everything I needed with Mechanize and Nokogiri. It's usually a better idea to work with simple tools when you're first grasping concepts so you don't get lost in the weeds of some high powered framework.</p>

<!--more-->


<p>Since it's late I'll let the code do the talking:</p>

<p>``` ruby crawler.rb
require 'mechanize'</p>

<h1>Create a new instance of Mechanize and grab our page</h1>

<p>agent = Mechanize.new
page = agent.get('http://robdodson.me/blog/archives/')</p>

<h1>Find all the links on the page that are contained within</h1>

<h1>h1 tags.</h1>

<p>post_links = page.links.find_all { |l| l.attributes.parent.name == 'h1' }</p>

<h1>Click on one of our post links and store the response</h1>

<p>post = post_links[1].click
doc = page.parser # Same as Nokogiri::HTML(page.body)
p doc
```</p>

<p>This code is hopefully easy enough to digest. After I get the page I find all of the links which are wrapped inside of an <code>h1</code>. Just as an example I <code>click</code> a link from the list using Array syntax and store the response in another var. You <em>could</em> click all of the links by iterating through the post_links object, and that's what we'll tackle tomorrow. For now I just follow 1 link and use a convenience method to parse the page with Nokogiri. After that we have a Nokogiri <code>doc</code> ready to be manipulated however we see fit.</p>

<p><a href="https://gist.github.com/2958538">Here's a link to the Gist</a> if you'd like to tweak or play with the code. Pop it into <code>irb</code> and give it a shot. - Rob</p>

<p>You should follow me on Twitter <a href="http://twitter.com/rob_dodson">here.</a></p>

<ul class="personal-stats">
    <li>Mood: Tired, Introspective</li>
    <li>Sleep: 4.5</li>
    <li>Hunger: 2</li>
    <li>Coffee: 1</li>
</ul>

]]></content>
  </entry>
  
</feed>
